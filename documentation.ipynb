{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "The objective of this repository is to build a machine learning model that is capable of making predictions on the movement of asset prices. Once a model is made that is of a high enough standard, it will be deployed into production to make predictions on an ongoing basis. For this project, I will be using Databricks to leverage the ML cluster as well as taking advantage of its distributed nature and user features such as AutoML, MLflow and visualisations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be building models that will predict the price change of different assets in the hope of being able to select a portfolio using these various models in combination. To start with, I am going to focus on the price of Apple. This is because it has a sufficient amount of liquidity to trade and data is readily available. My aim for now is to predict the change in stock price for the next day. Everything outside of that is open to testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main tool I will be using is Databricks. It has a few features which I think will be useful for me including:\n",
    "- Parallel Computing: I will be learning to use pyspark (Python API on Spark computing) in order to distribute my operations between nodes, allowing for more efficient querying and transforming on the data, which could be fairly large considering how far back I would like to go\n",
    "- AutoML: I would take advantage of the AutoML offering in order to build baseline models for each dataset I use, giving me a fast way of knowing what the predictive power of my data might be\n",
    "- MLflow: I will be leaning heavily on MLflow in order to track experiments and different models I build so that I know what direction to go in and know whether a model I built is the best yet; it will also play a large role when it comes to deployment\n",
    "\n",
    "I am also hoping to utilise Numba, a Python library (built into Databricks ML Runtime) that is capable of making my code more efficient when it comes to executing. It does this by making full use of the NVIDIA GPU attached to the cluster to distribute work efficiently between threads. \n",
    "\n",
    "Another tool I am interested in is testing for my code. I want to implement testing into my notebook so that I can quickly see where my code isn't outputting the result I expected. This is important as mistakes in price predictions can be costly if acted upon and so robustness and correctness of my code is of high importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, I am creating a Spark Session. This will allow me to utilise the computing architecture of Apache Spark, for example by creating dataframes that can be parallelized for operations, transformations and querying. I am also creating  a database 'aaronxwalker' in order to store my curated data and different versions of data.\n",
    "\n",
    "I am using the Python package yfinance to import price history for Apple. To begin with I am getting data from the start of 2015 till now; this will hopefully provide me with enough meaningful data to build some complex models but also being slightly faster than working on more data and I do have the option to go back for more should I need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My target column is the percentage change of the stock price from the close of day t-1 to the close of day t. I have chosen Close because it gives me a chance to bet on the outcome whilst the market is open, whereas betting on the Open means I can't take advantage of a difference in price overnight as the market is shut. The reason I am using percentage change is that it is indifferent to the price of the stock, which vary among stocks but has no meaning. It also is likely to have a recognisable distribution which might come in useful to certain parametric models later on.\n",
    "\n",
    "I will also look at the performance of predicting on log returns, which supposedly have even more of a normal distribution and might strengthen the results of some models. It also has an additive property meaning I can simply add the log returns of several days to get the cumulative returns for those days. However, I have yet to test this target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, I am using the features that are provided by yfinance. This includes basic time-series information on the stock price, including open, high, low, volume, dividends and stock splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lagging Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important not to use features that we won't have access to in time for inference. For example, we don't want to use the volume for day t to make predictions on the target for day t as the volume won't be accessable till the end of the day, by which time it will be too late to make a prediction. To this end, I have decided to lag each of the above features by a day so that I can use the previous days information to make inferences for the next day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas to improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I'm struggling to improve the performance of my model, here are some ideas I plan to try:\n",
    "- increase the number of useful features in my model (gather more external data)\n",
    "- try to split up the data into different periods so that all the data used comes from the same distribution\n",
    "- make a classification model to predict +/- returns for the day\n",
    "- change the time period I am predicting over e.g. predict returns over the next month instead of next day\n",
    "- explore different models\n",
    "- read a book on time-series\n",
    "- try a different asset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
